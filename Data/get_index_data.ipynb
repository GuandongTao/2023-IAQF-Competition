{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8e08a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "symbols = ['SPY', '^RUT', '^DJI', '^STI', '^N225', '^IXIC', '^HSI', '^NSEI', '^STOXX50E']\n",
    "\n",
    "for symbol in symbols:\n",
    "    df = yf.download(symbol, start=\"2013-02-07\", end=\"2023-02-07\")\n",
    "    df = df[['Adj Close']].copy()\n",
    "    df.reset_index(inplace=True)\n",
    "    df['date'] = df['Date'].dt.date\n",
    "    df.rename(columns={'Date': 'datetime', 'Adj Close': symbol + '_adj_close'}, inplace=True)\n",
    "    df.drop(columns=['datetime'], inplace=True)\n",
    "\n",
    "    df.to_csv(symbol + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3aa6a8bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'date'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [49]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m merged_df \u001b[38;5;241m=\u001b[39m dfs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(dfs)):\n\u001b[1;32m---> 12\u001b[0m     merged_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmerged_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdfs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m merged_df\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:107\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mleft : DataFrame or named Series\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     91\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    105\u001b[0m     validate: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    106\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m--> 107\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[43m_MergeOperation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:700\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    693\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cross \u001b[38;5;241m=\u001b[39m cross_col\n\u001b[0;32m    695\u001b[0m \u001b[38;5;66;03m# note this function has side effects\u001b[39;00m\n\u001b[0;32m    696\u001b[0m (\n\u001b[0;32m    697\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_join_keys,\n\u001b[0;32m    698\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_join_keys,\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjoin_names,\n\u001b[1;32m--> 700\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_merge_keys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# validate the merge keys dtypes. We may need to coerce\u001b[39;00m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;66;03m# to avoid incompatible dtypes\u001b[39;00m\n\u001b[0;32m    704\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_coerce_merge_keys()\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:1097\u001b[0m, in \u001b[0;36m_MergeOperation._get_merge_keys\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1095\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_rkey(rk):\n\u001b[0;32m   1096\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m rk \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1097\u001b[0m         right_keys\u001b[38;5;241m.\u001b[39mappend(\u001b[43mright\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_label_or_level_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrk\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1098\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1099\u001b[0m         \u001b[38;5;66;03m# work-around for merge_asof(right_index=True)\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m         right_keys\u001b[38;5;241m.\u001b[39mappend(right\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:1840\u001b[0m, in \u001b[0;36mNDFrame._get_label_or_level_values\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1838\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\u001b[38;5;241m.\u001b[39mget_level_values(key)\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m   1839\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1840\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[0;32m   1842\u001b[0m \u001b[38;5;66;03m# Check for duplicates\u001b[39;00m\n\u001b[0;32m   1843\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m values\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'date'"
     ]
    }
   ],
   "source": [
    "# list to store the dataframes\n",
    "dfs = []\n",
    "\n",
    "# loop over the file names and read each file into a dataframe\n",
    "for symbol in symbols:\n",
    "    df = pd.read_csv(symbol + \".csv\")\n",
    "    dfs.append(df)\n",
    "\n",
    "# merge the dataframes on the 'date' column\n",
    "merged_df = dfs[0]\n",
    "for i in range(1, len(dfs)):\n",
    "    merged_df = pd.merge(merged_df, dfs[i], on='date')\n",
    "\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a85e94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv(\"merged.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1eaf9e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>_Adj_Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>214.931459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>217.476164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-08</td>\n",
       "      <td>214.827063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-09</td>\n",
       "      <td>217.735043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-10</td>\n",
       "      <td>217.799497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>2023-02-13</td>\n",
       "      <td>208.491926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>2023-02-14</td>\n",
       "      <td>208.579372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>2023-02-15</td>\n",
       "      <td>206.794895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>2023-02-16</td>\n",
       "      <td>206.839574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>2023-02-17</td>\n",
       "      <td>205.208540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>763 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  _Adj_Close\n",
       "0    2020-01-06  214.931459\n",
       "1    2020-01-07  217.476164\n",
       "2    2020-01-08  214.827063\n",
       "3    2020-01-09  217.735043\n",
       "4    2020-01-10  217.799497\n",
       "..          ...         ...\n",
       "758  2023-02-13  208.491926\n",
       "759  2023-02-14  208.579372\n",
       "760  2023-02-15  206.794895\n",
       "761  2023-02-16  206.839574\n",
       "762  2023-02-17  205.208540\n",
       "\n",
       "[763 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "# Download the Nikkei 225 data\n",
    "nikkei = yf.download(\"^N225\", start=\"2020-01-01\", end=\"2023-02-19\")\n",
    "\n",
    "# Download JPY/USD exchange rate data\n",
    "jpy_usd_rate = yf.download(\"JPY=X\", start=\"2020-01-01\", end=\"2023-02-19\")\n",
    "\n",
    "# Join the dataframes on date index\n",
    "nikkei_jpy = pd.DataFrame(nikkei['Adj Close'])\n",
    "nikkei_jpy.reset_index(inplace=True)\n",
    "nikkei_jpy['date'] = nikkei_jpy['Date'].dt.date\n",
    "nikkei_jpy.rename(columns={'Date': 'datetime', 'Adj Close': 'AdjClose'}, inplace=True)\n",
    "nikkei_jpy.drop(columns=['datetime'], inplace=True)\n",
    "\n",
    "\n",
    "jpy_usd = pd.DataFrame(jpy_usd_rate['Close'])\n",
    "jpy_usd.reset_index(inplace=True)\n",
    "jpy_usd['date'] = jpy_usd['Date'].dt.date\n",
    "jpy_usd.rename(columns={'Date': 'datetime', 'Adj Close': 'AdjClose'}, inplace=True)\n",
    "jpy_usd.drop(columns=['datetime'], inplace=True)\n",
    "\n",
    "\n",
    "nikkei_usd = pd.merge(nikkei_jpy, jpy_usd, how='inner', left_on = 'date', right_on = 'date')\n",
    "\n",
    "# Multiply the columns to convert to USD\n",
    "nikkei_usd['_Adj_Close'] = nikkei_usd['AdjClose'] / nikkei_usd['Close']\n",
    "\n",
    "nikkei_usd[['date','_Adj_Close']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "797894b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "SPY data exported to SPY.csv\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "^RUT data exported to ^RUT.csv\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "^DJI data exported to ^DJI.csv\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "^STI data exported to ^STI.csv\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "^N225 data exported to ^N225.csv\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "^IXIC data exported to ^IXIC.csv\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "^HSI data exported to ^HSI.csv\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "^NSEI data exported to ^NSEI.csv\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "^STOXX50E data exported to ^STOXX50E.csv\n"
     ]
    }
   ],
   "source": [
    "def getdata(symbol):\n",
    "    # Download data\n",
    "    df = yf.download(symbol, start=\"2013-01-20\", end=\"2023-02-07\")\n",
    "    \n",
    "    # Download exchange rate data\n",
    "    if symbol == '^N225':\n",
    "        jpy_usd_rate = yf.download(\"JPY=X\", start=\"2013-01-20\", end=\"2023-02-07\")\n",
    "    elif symbol == '^HSI':\n",
    "        jpy_usd_rate = yf.download(\"HKD=X\", start=\"2013-01-20\", end=\"2023-02-07\")\n",
    "    elif symbol == '^NSEI':\n",
    "        jpy_usd_rate = yf.download(\"INR=X\", start=\"2013-01-20\", end=\"2023-02-07\")\n",
    "    elif symbol == '^STI':\n",
    "        jpy_usd_rate = yf.download(\"SGD=X\", start=\"2013-01-20\", end=\"2023-02-07\")\n",
    "    elif symbol == '^STOXX50E':\n",
    "        jpy_usd_rate = yf.download(\"EUR=X\", start=\"2013-01-20\", end=\"2023-02-07\")\n",
    "    else:\n",
    "        df_jpy = pd.DataFrame(df['Adj Close'])\n",
    "        df_jpy.reset_index(inplace=True)\n",
    "        df_jpy['date'] = df_jpy['Date'].dt.date\n",
    "        df_jpy.rename(columns={'Date': 'datetime', 'Adj Close': 'AdjClose'}, inplace=True)\n",
    "        df_jpy.drop(columns=['datetime'], inplace=True)\n",
    "        return(pd.DataFrame(df_jpy[['date', 'AdjClose']]))\n",
    "    \n",
    "    # Join the dataframes on date index\n",
    "    df_jpy = pd.DataFrame(df['Adj Close'])\n",
    "    df_jpy.reset_index(inplace=True)\n",
    "    df_jpy['date'] = df_jpy['Date'].dt.date\n",
    "    df_jpy.rename(columns={'Date': 'datetime', 'Adj Close': 'AdjClose'}, inplace=True)\n",
    "    df_jpy.drop(columns=['datetime'], inplace=True)\n",
    "    #print(df_jpy)\n",
    "\n",
    "    jpy_usd = pd.DataFrame(jpy_usd_rate['Close'])\n",
    "    jpy_usd.reset_index(inplace=True)\n",
    "    jpy_usd['date'] = jpy_usd['Date'].dt.date\n",
    "    jpy_usd.rename(columns={'Date': 'datetime', 'Close': 'Close'}, inplace=True)\n",
    "    jpy_usd.drop(columns=['datetime'], inplace=True)\n",
    "    #print(jpy_usd)\n",
    "\n",
    "\n",
    "    df_usd = pd.merge(df_jpy, jpy_usd, how='inner', left_on = 'date', right_on = 'date')\n",
    "\n",
    "    # Multiply the columns to convert to USD\n",
    "    df_usd['_Adj_Close'] = df_usd['AdjClose'] / df_usd['Close']\n",
    "\n",
    "    # Add dataframe to dictionary\n",
    "    return(pd.DataFrame(df_usd[['date', '_Adj_Close']]))\n",
    "\n",
    "def export_data_to_csv(symbol):\n",
    "    # Download data\n",
    "    df = getdata(symbol)\n",
    "    \n",
    "    # Export data to CSV file\n",
    "    df.to_csv(symbol + \".csv\", index=False)\n",
    "    \n",
    "    # Print a message to confirm export\n",
    "    print(f\"{symbol} data exported to {symbol}.csv\")\n",
    "\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "# Define list of symbols\n",
    "symbols = ['SPY', '^RUT', '^DJI', '^STI', '^N225', '^IXIC', '^HSI', '^NSEI', '^STOXX50E']\n",
    "\n",
    "# Create empty dictionary to store dataframes\n",
    "data = pd.DataFrame()\n",
    "\n",
    "# Download and convert data for each symbol\n",
    "for symbol in symbols:\n",
    "    export_data_to_csv(symbol)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "529213e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bowen\\AppData\\Local\\Temp\\ipykernel_13668\\2202296434.py:14: FutureWarning: Passing 'suffixes' which cause duplicate columns {'AdjClose_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  merged_df = pd.merge(merged_df, dfs[i], on='date')\n",
      "C:\\Users\\Bowen\\AppData\\Local\\Temp\\ipykernel_13668\\2202296434.py:14: FutureWarning: Passing 'suffixes' which cause duplicate columns {'_Adj_Close_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  merged_df = pd.merge(merged_df, dfs[i], on='date')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>SPY</th>\n",
       "      <th>RUT</th>\n",
       "      <th>DJI</th>\n",
       "      <th>STI</th>\n",
       "      <th>N225</th>\n",
       "      <th>IXIC</th>\n",
       "      <th>HSI</th>\n",
       "      <th>NSEI</th>\n",
       "      <th>STOXX50E</th>\n",
       "      <th>MID</th>\n",
       "      <th>NDX</th>\n",
       "      <th>NYA</th>\n",
       "      <th>OEX</th>\n",
       "      <th>RUA</th>\n",
       "      <th>RUI</th>\n",
       "      <th>SML</th>\n",
       "      <th>SP1500</th>\n",
       "      <th>SPX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Date, SPY, RUT, DJI, STI, N225, IXIC, HSI, NSEI, STOXX50E, MID, NDX, NYA, OEX, RUA, RUI, SML, SP1500, SPX]\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list to store the dataframes\n",
    "dfs = []\n",
    "\n",
    "# loop over the file names and read each file into a dataframe\n",
    "for symbol in symbols:\n",
    "    df = pd.read_csv(symbol + \".csv\")\n",
    "    dfs.append(df)\n",
    "    \n",
    "df = pd.read_csv(\"all_data.csv\")\n",
    "dfs.append(df)\n",
    "# merge the dataframes on the 'date' column\n",
    "merged_df = dfs[0]\n",
    "for i in range(1, len(dfs)):\n",
    "    merged_df = pd.merge(merged_df, dfs[i], on='date')\n",
    "\n",
    "merged_df.columns = ['Date', 'SPY', 'RUT', 'DJI', 'STI', 'N225', 'IXIC', 'HSI', 'NSEI', 'STOXX50E'\n",
    "                    , 'MID', 'NDX', 'NYA', 'OEX', 'RUA', 'RUI', 'SML', 'SP1500', 'SPX']\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "87d3f5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv(\"merged.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4013a594",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "time data '2022-01-01' does not match format '%m/%d/%Y' (match)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:510\u001b[0m, in \u001b[0;36m_to_datetime_with_format\u001b[1;34m(arg, orig_arg, name, tz, fmt, exact, errors, infer_datetime_format)\u001b[0m\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 510\u001b[0m     values, tz \u001b[38;5;241m=\u001b[39m \u001b[43mconversion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatetime_to_datetime64\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    511\u001b[0m     dta \u001b[38;5;241m=\u001b[39m DatetimeArray(values, dtype\u001b[38;5;241m=\u001b[39mtz_to_dtype(tz))\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\tslibs\\conversion.pyx:360\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.conversion.datetime_to_datetime64\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Unrecognized value type: <class 'datetime.date'>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m df_jpy \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall_data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m df_jpy[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mm/\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mY\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mdate\n\u001b[0;32m      3\u001b[0m df_jpy\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1051\u001b[0m, in \u001b[0;36mto_datetime\u001b[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mmap(cache_array)\n\u001b[0;32m   1050\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1051\u001b[0m         values \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1052\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39m_constructor(values, index\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mindex, name\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m   1053\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, (ABCDataFrame, abc\u001b[38;5;241m.\u001b[39mMutableMapping)):\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:394\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[1;34m(arg, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[0;32m    391\u001b[0m         \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    393\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 394\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_to_datetime_with_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    395\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morig_arg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfer_datetime_format\u001b[49m\n\u001b[0;32m    396\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    398\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:514\u001b[0m, in \u001b[0;36m_to_datetime_with_format\u001b[1;34m(arg, orig_arg, name, tz, fmt, exact, errors, infer_datetime_format)\u001b[0m\n\u001b[0;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DatetimeIndex\u001b[38;5;241m.\u001b[39m_simple_new(dta, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[0;32m    513\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m--> 514\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:501\u001b[0m, in \u001b[0;36m_to_datetime_with_format\u001b[1;34m(arg, orig_arg, name, tz, fmt, exact, errors, infer_datetime_format)\u001b[0m\n\u001b[0;32m    498\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m _box_as_indexlike(result, utc\u001b[38;5;241m=\u001b[39mutc, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[0;32m    500\u001b[0m     \u001b[38;5;66;03m# fallback\u001b[39;00m\n\u001b[1;32m--> 501\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_array_strptime_with_fallback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfer_datetime_format\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n\u001b[0;32m    506\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    507\u001b[0m     \u001b[38;5;66;03m# Fallback to try to convert datetime objects if timezone-aware\u001b[39;00m\n\u001b[0;32m    508\u001b[0m     \u001b[38;5;66;03m#  datetime objects are found without passing `utc=True`\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:437\u001b[0m, in \u001b[0;36m_array_strptime_with_fallback\u001b[1;34m(arg, name, tz, fmt, exact, errors, infer_datetime_format)\u001b[0m\n\u001b[0;32m    434\u001b[0m utc \u001b[38;5;241m=\u001b[39m tz \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutc\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    436\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 437\u001b[0m     result, timezones \u001b[38;5;241m=\u001b[39m \u001b[43marray_strptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    438\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mZ\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m fmt \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mz\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m fmt:\n\u001b[0;32m    439\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _return_parsed_timezone_results(result, timezones, tz, name)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\tslibs\\strptime.pyx:150\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: time data '2022-01-01' does not match format '%m/%d/%Y' (match)"
     ]
    }
   ],
   "source": [
    "df_jpy = pd.read_csv(\"all_data.csv\")\n",
    "df_jpy['date'] = pd.to_datetime(df['date'], format='%m/%d/%Y').dt.date\n",
    "df_jpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5385dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
